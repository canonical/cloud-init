Description: Retain setuptools build backend on stable series.
 Avoid change in behavior in tip of main which switched to meson.build
 as the default build backend. Retain the minimal patchset necessary
 to retain setuptools pybuild default build backend.
Author: Chad Smith <chad.smith@canonical.com>
Origin: backport
Last-Update: 2025-08-25
--- a/pyproject.toml
+++ b/pyproject.toml
@@ -1,6 +1,6 @@
-[build-system]  # See meson.build. Empty build-system to avoid RTD builds
-build-backend = ""
-requires = []
+[build-system]
+requires = ["setuptools"]
+build-backend = "setuptools.build_meta"
 
 [tool.black]
 line-length = 79
--- /dev/null
+++ b/setup.py
@@ -0,0 +1,342 @@
+# Copyright (C) 2009 Canonical Ltd.
+# Copyright (C) 2012 Yahoo! Inc.
+#
+# Author: Soren Hansen <soren@canonical.com>
+# Author: Joshua Harlow <harlowja@yahoo-inc.com>
+#
+# This file is part of cloud-init.  See LICENSE file for license information.
+
+# Distutils magic for ec2-init
+
+import atexit
+import os
+import platform
+import shutil
+import subprocess
+import sys
+import tempfile
+from glob import glob
+
+import setuptools
+from setuptools.command.egg_info import egg_info
+from setuptools.command.install import install
+
+# Python-path here is a little unpredictable as setup.py could be run
+# from a directory other than the root of the repo, so ensure we can find
+# our utils
+sys.path.insert(0, os.path.dirname(os.path.realpath(__file__)))
+# isort: off
+from setup_utils import (  # noqa: E402
+    get_version,
+    is_f,
+    is_generator,
+    pkg_config_read,
+    read_requires,
+)
+
+# isort: on
+del sys.path[0]
+
+# pylint: disable=W0402
+try:
+    from setuptools.errors import DistutilsError
+except ImportError:
+    from distutils.errors import DistutilsArgError as DistutilsError
+# pylint: enable=W0402
+
+RENDERED_TMPD_PREFIX = "RENDERED_TEMPD"
+VARIANT = None
+PREFIX = None
+
+
+def render_tmpl(template, mode=None, is_yaml=False):
+    """render template into a tmpdir under same dir as setup.py
+
+    This is rendered to a temporary directory under the top level
+    directory with the name 'cloud.cfg'.  The reason for not just rendering
+    to config/cloud.cfg is for a.) don't want to write over contents
+    in that file if user had something there. b.) debuild will complain
+    that files are different outside of the debian directory."""
+
+    # newer versions just use install.
+    if "install" not in sys.argv:
+        return template
+
+    tmpl_ext = ".tmpl"
+    # we may get passed a non-template file, just pass it back
+    if not template.endswith(tmpl_ext):
+        return template
+
+    topdir = os.path.dirname(sys.argv[0])
+    tmpd = tempfile.mkdtemp(dir=topdir, prefix=RENDERED_TMPD_PREFIX)
+    atexit.register(shutil.rmtree, tmpd)
+    bname = os.path.basename(template)
+    ename, ext = os.path.splitext(bname)
+    if ext == tmpl_ext:
+        bname = ename
+    fpath = os.path.join(tmpd, bname)
+    cmd_variant = []
+    cmd_prefix = []
+    if VARIANT:
+        cmd_variant = ["--variant", VARIANT]
+    if PREFIX:
+        cmd_prefix = ["--prefix", PREFIX]
+    subprocess.run(  # nosec B603
+        [
+            sys.executable,
+            "./tools/render-template",
+            *(["--is-yaml"] if is_yaml else []),
+            *cmd_prefix,
+            *cmd_variant,
+            *[template, fpath],
+        ],
+        check=True,
+    )
+    if mode:
+        os.chmod(fpath, mode)
+    # return path relative to setup.py
+    return os.path.join(os.path.basename(tmpd), bname)
+
+
+# User can set the variant for template rendering
+for a in sys.argv:
+    if a.startswith("--distro"):
+        idx = sys.argv.index(a)
+        if "=" in a:
+            _, VARIANT = a.split("=")
+            del sys.argv[idx]
+        else:
+            VARIANT = sys.argv[idx + 1]
+            del sys.argv[idx + 1]
+            sys.argv.remove("--distro")
+
+# parse PREFIX and pass it on from render_tmpl()
+for a in sys.argv:
+    if a.startswith("--prefix"):
+        idx = sys.argv.index(a)
+        if "=" in a:
+            _, PREFIX = a.split("=")
+        else:
+            PREFIX = sys.argv[idx + 1]
+
+INITSYS_FILES = {
+    "sysvinit": lambda: [f for f in glob("sysvinit/redhat/*") if is_f(f)],
+    "sysvinit_freebsd": lambda: [
+        render_tmpl(f, mode=0o755)
+        for f in glob("sysvinit/freebsd/*")
+        if is_f(f)
+    ],
+    "sysvinit_netbsd": lambda: [
+        render_tmpl(f, mode=0o755)
+        for f in glob("sysvinit/netbsd/*")
+        if is_f(f)
+    ],
+    "sysvinit_openbsd": lambda: [
+        render_tmpl(f, mode=0o755)
+        for f in glob("sysvinit/openbsd/*")
+        if is_f(f)
+    ],
+    "sysvinit_deb": lambda: [f for f in glob("sysvinit/debian/*") if is_f(f)],
+    "sysvinit_openrc": lambda: [
+        f for f in glob("sysvinit/openrc/*") if is_f(f)
+    ],
+    "sysvinit_openrc.dep": lambda: ["tools/cloud-init-hotplugd"],
+    "systemd": lambda: [
+        render_tmpl(f)
+        for f in (
+            glob("systemd/*.tmpl")
+            + glob("systemd/*.service")
+            + glob("systemd/*.socket")
+            + glob("systemd/*.target")
+        )
+        if (is_f(f) and not is_generator(f))
+    ],
+    "systemd.generators": lambda: [
+        render_tmpl(f, mode=0o755)
+        for f in glob("systemd/*")
+        if is_f(f) and is_generator(f)
+    ],
+}
+INITSYS_ROOTS = {
+    "sysvinit": "etc/rc.d/init.d",
+    "sysvinit_freebsd": "usr/local/etc/rc.d",
+    "sysvinit_netbsd": "usr/local/etc/rc.d",
+    "sysvinit_openbsd": "etc/rc.d",
+    "sysvinit_deb": "etc/init.d",
+    "sysvinit_openrc": "etc/init.d",
+    "sysvinit_openrc.dep": "usr/lib/cloud-init",
+    "systemd": pkg_config_read("systemd", "systemdsystemunitdir"),
+    "systemd.generators": pkg_config_read(
+        "systemd", "systemdsystemgeneratordir"
+    ),
+}
+INITSYS_TYPES = sorted([f.partition(".")[0] for f in INITSYS_ROOTS.keys()])
+
+
+# Install everything in the right location and take care of Linux (default) and
+# FreeBSD systems.
+USR = "usr"
+ETC = "etc"
+USR_LIB_EXEC = "usr/lib"
+LIB = "lib"
+if os.uname()[0] in ["FreeBSD", "DragonFly", "OpenBSD"]:
+    USR = "usr/local"
+    USR_LIB_EXEC = "usr/local/lib"
+elif os.path.isfile("/etc/redhat-release"):
+    USR_LIB_EXEC = "usr/libexec"
+elif os.path.isfile("/etc/system-release-cpe"):
+    with open("/etc/system-release-cpe") as f:
+        cpe_data = f.read().rstrip().split(":")
+        (cpe_vendor, cpe_product, cpe_version) = cpe_data[3:6]
+        if cpe_vendor == "amazon":
+            USR_LIB_EXEC = "usr/libexec"
+
+
+class MyEggInfo(egg_info):
+    """This makes sure to not include the rendered files in SOURCES.txt."""
+
+    def find_sources(self):
+        egg_info.find_sources(self)
+        # update the self.filelist.
+        self.filelist.exclude_pattern(
+            RENDERED_TMPD_PREFIX + ".*", is_regex=True
+        )
+        # but since mfname is already written we have to update it also.
+        mfname = os.path.join(self.egg_info, "SOURCES.txt")
+        if os.path.exists(mfname):
+            with open(mfname) as fp:
+                files = [
+                    f for f in fp if not f.startswith(RENDERED_TMPD_PREFIX)
+                ]
+            with open(mfname, "w") as fp:
+                fp.write("".join(files))
+
+
+# TODO: Is there a better way to do this??
+class InitsysInstallData(install):
+    init_system = None
+    user_options = install.user_options + [
+        # This will magically show up in member variable 'init_sys'
+        (
+            "init-system=",
+            None,
+            "init system(s) to configure (%s) [default: None]"
+            % ", ".join(INITSYS_TYPES),
+        ),
+    ]
+
+    def initialize_options(self):
+        install.initialize_options(self)
+        self.init_system = ""
+
+    def finalize_options(self):
+        install.finalize_options(self)
+
+        if self.init_system and isinstance(self.init_system, str):
+            self.init_system = self.init_system.split(",")
+
+        if not self.init_system and not platform.system().endswith("BSD"):
+            self.init_system = ["systemd"]
+
+        bad = [f for f in self.init_system if f not in INITSYS_TYPES]
+        if bad:
+            raise DistutilsError("Invalid --init-system: %s" % ",".join(bad))
+
+        for system in self.init_system:
+            # add data files for anything that starts with '<system>.'
+            datakeys = [
+                k for k in INITSYS_ROOTS if k.partition(".")[0] == system
+            ]
+            for k in datakeys:
+                files = INITSYS_FILES[k]()
+                if not files:
+                    continue
+                self.distribution.data_files.append((INITSYS_ROOTS[k], files))
+        # Force that command to reinitialize (with new file list)
+        self.distribution.reinitialize_command("install_data", True)
+
+
+USR = "/" + USR
+ETC = "/" + ETC
+USR_LIB_EXEC = "/" + USR_LIB_EXEC
+LIB = "/" + LIB
+for k in INITSYS_ROOTS.keys():
+    INITSYS_ROOTS[k] = "/" + INITSYS_ROOTS[k]
+
+data_files = [
+    (ETC + "/cloud", [render_tmpl("config/cloud.cfg.tmpl", is_yaml=True)]),
+    (ETC + "/cloud/clean.d", glob("config/clean.d/*")),
+    (ETC + "/cloud/cloud.cfg.d", glob("config/cloud.cfg.d/*")),
+    (ETC + "/cloud/templates", glob("templates/*")),
+    (
+        USR_LIB_EXEC + "/cloud-init",
+        [
+            "tools/ds-identify",
+            "tools/hook-hotplug",
+            "tools/uncloud-init",
+            "tools/write-ssh-key-fingerprints",
+        ],
+    ),
+    (
+        USR + "/share/bash-completion/completions",
+        ["bash_completion/cloud-init"],
+    ),
+    (USR + "/share/doc/cloud-init", [f for f in glob("doc/*") if is_f(f)]),
+    (
+        USR + "/share/doc/cloud-init/examples",
+        [f for f in glob("doc/examples/*") if is_f(f)],
+    ),
+    (
+        USR + "/share/doc/cloud-init/examples/seed",
+        [f for f in glob("doc/examples/seed/*") if is_f(f)],
+    ),
+    (
+        USR + "/share/doc/cloud-init/module-docs",
+        [f for f in glob("doc/module-docs/*", recursive=True) if is_f(f)],
+    ),
+]
+if not platform.system().endswith("BSD"):
+    RULES_PATH = pkg_config_read("udev", "udevdir")
+    RULES_PATH = "/" + RULES_PATH
+
+    data_files.extend(
+        [
+            (RULES_PATH + "/rules.d", [f for f in glob("udev/*.rules")]),
+            (
+                INITSYS_ROOTS["systemd"] + "/sshd-keygen@.service.d/",
+                ["systemd/disable-sshd-keygen-if-cloud-init-active.conf"],
+            ),
+        ]
+    )
+# Use a subclass for install that handles
+# adding on the right init system configuration files
+cmdclass = {
+    "install": InitsysInstallData,
+    "egg_info": MyEggInfo,
+}
+
+requirements = read_requires()
+
+setuptools.setup(
+    name="cloud-init",
+    version=get_version(),
+    description="Cloud instance initialization magic",
+    author="Scott Moser",
+    author_email="scott.moser@canonical.com",
+    url="http://launchpad.net/cloud-init/",
+    package_data={
+        "": ["*.json"],
+    },
+    packages=setuptools.find_packages(exclude=["tests.*", "tests"]),
+    scripts=["tools/cloud-init-per"],
+    license="Dual-licensed under GPLv3 or Apache 2.0",
+    data_files=data_files,
+    install_requires=requirements,
+    cmdclass=cmdclass,
+    entry_points={
+        "console_scripts": [
+            "cloud-init = cloudinit.cmd.main:main",
+            "cloud-id = cloudinit.cmd.cloud_id:main",
+        ],
+    },
+)
--- /dev/null
+++ b/setup_utils.py
@@ -0,0 +1,60 @@
+import os
+import subprocess
+import sys
+from typing import List
+
+
+def is_f(p: str) -> bool:
+    return os.path.isfile(p)
+
+
+def is_generator(p: str) -> bool:
+    return "-generator" in p
+
+
+def pkg_config_read(library: str, var: str) -> str:
+    pkg_config = "pkg-config"
+
+    if os.getenv("PKG_CONFIG"):
+        pkg_config = os.getenv("PKG_CONFIG")
+
+    fallbacks = {
+        "systemd": {
+            "systemdsystemconfdir": "/etc/systemd/system",
+            "systemdsystemunitdir": "/usr/lib/systemd/system",
+            "systemdsystemgeneratordir": "/usr/lib/systemd/system-generators",
+        },
+        "udev": {
+            "udevdir": "/usr/lib/udev",
+        },
+    }
+    cmd = [pkg_config, f"--variable={var}", library]
+    try:
+        path = subprocess.check_output(cmd).decode("utf-8")  # nosec B603
+        path = path.strip()
+    except Exception:
+        path = fallbacks[library][var]
+    if path.startswith("/"):
+        path = path[1:]
+
+    return path
+
+
+def version_to_pep440(version: str) -> str:
+    # read-version can spit out something like 22.4-15-g7f97aee24
+    # which is invalid under PEP 440. If we replace the first - with a +
+    # that should give us a valid version.
+    return version.replace("-", "+", 1)
+
+
+def get_version() -> str:
+    cmd = [sys.executable, "tools/read-version"]
+    ver = subprocess.check_output(cmd)  # B603
+    version = ver.decode("utf-8").strip()
+    return version_to_pep440(version)
+
+
+def read_requires() -> List[str]:
+    cmd = [sys.executable, "tools/read-dependencies"]
+    deps = subprocess.check_output(cmd)  # nosec B603
+    return deps.decode("utf-8").splitlines()
--- a/test-requirements.txt
+++ b/test-requirements.txt
@@ -11,9 +11,9 @@ pytest
 pytest-cov
 pytest-mock
 pytest-xdist
+setuptools
 jsonschema
 responses
-packaging
 passlib
 
 # This one is currently used only by the CloudSigma and SmartOS datasources.
--- /dev/null
+++ b/tools/read-version
@@ -0,0 +1,153 @@
+#!/usr/bin/env python3
+
+# This script has tests. Run pytest on the tools directory if you make changes
+
+import json
+import os
+import re
+import subprocess
+import sys
+from shutil import which
+
+repo_base_dir = os.path.abspath(os.path.join(os.path.dirname(__file__), ".."))
+sys.path.insert(0, repo_base_dir)
+
+from cloudinit import version as ci_version  # noqa: E402
+
+
+def tiny_p(cmd):
+    stderr = subprocess.PIPE
+    return subprocess.check_output(
+        cmd, stderr=stderr, stdin=None, universal_newlines=True
+    )
+
+
+def is_gitdir(path):
+    # Return boolean indicating if path is a git tree.
+    git_meta = os.path.join(path, ".git")
+    if os.path.isdir(git_meta):
+        return True
+    if os.path.exists(git_meta):
+        # in a git worktree, .git is a file with 'gitdir: x'
+        with open(git_meta, "rb") as fp:
+            if b"gitdir:" in fp.read():
+                return True
+    return False
+
+
+def get_version_details(version, version_long, is_release_branch_ci):
+    release = None
+    extra = None
+    commit = None
+    distance = None
+
+    # Should match upstream version number. E.g., 23.1 or 23.1.2
+    short_regex = r"(\d+\.\d+\.?\d*)"
+    # Should match version including upstream version, distance, and commit
+    # E.g., 23.1.2-10-g12ab34cd
+    long_regex = r"(\d+\.\d+\.?\d*){1}.*-(\d+)+-g([a-f0-9]{8}){1}.*"
+
+    short_match = re.search(short_regex, version)
+    long_match = re.search(long_regex, version_long)
+    if long_match:
+        release, distance, commit = long_match.groups()
+        extra = f"-{distance}-g{commit}"
+    elif short_match:
+        release = short_match.groups()[0]
+
+    return {
+        "release": release,
+        "version": version,
+        "version_long": version_long,
+        "extra": extra,
+        "commit": commit,
+        "distance": distance,
+        "is_release_branch_ci": is_release_branch_ci,
+    }
+
+
+def get_version_from_git(
+    src_version, major_minor_version, use_tags, is_release_branch_ci
+):
+    if is_gitdir(repo_base_dir) and which("git") and not is_release_branch_ci:
+        branch_name = tiny_p(
+            ["git", "rev-parse", "--abbrev-ref", "HEAD"]
+        ).strip()
+        if branch_name.startswith(f"upstream/{major_minor_version}"):
+            version = src_version
+            version_long = ""
+        else:
+            flags = ["--tags"] if use_tags else []
+            cmd = [
+                "git",
+                "describe",
+                branch_name,
+                "--abbrev=8",
+            ] + flags
+
+            try:
+                version = tiny_p(cmd).strip()
+                version_long = tiny_p(cmd + ["--long"]).strip()
+            except subprocess.CalledProcessError as e:
+                if not any(
+                    [
+                        "No tags can describe" in e.stderr,
+                        "cannot describe anything" in e.stderr,
+                    ]
+                ):
+                    raise
+                version = src_version
+                version_long = ""
+    else:
+        version = src_version
+        version_long = ""
+    return version, version_long
+
+
+def main(use_tags: bool = False, output_json: bool = False):
+    src_version = ci_version.version_string()
+    # upstream/MM.NN.x tracks our patch level releases so ignore trailing '.x'
+    major_minor_version = ".".join(src_version.split(".")[:2])
+
+    # If we're performing CI for a new release branch (which our tooling
+    # creates with an "upstream/" prefix), then we don't want to enforce
+    # strict version matching because we know it will fail.
+    github_ci_release_br = bool(
+        os.environ.get("GITHUB_HEAD_REF", "").startswith(
+            f"upstream/{major_minor_version}"
+        )
+    )
+    travis_ci_release_br = bool(
+        os.environ.get("TRAVIS_PULL_REQUEST_BRANCH", "").startswith(
+            "upstream/"
+        )
+    )
+    is_release_branch_ci = github_ci_release_br or travis_ci_release_br
+
+    version, version_long = get_version_from_git(
+        src_version=src_version,
+        major_minor_version=major_minor_version,
+        use_tags=use_tags,
+        is_release_branch_ci=is_release_branch_ci,
+    )
+
+    details = get_version_details(version, version_long, is_release_branch_ci)
+
+    if output_json:
+        return json.dumps(details, indent=1)
+
+    output = ""
+    if details["release"]:
+        output += details["release"]
+    if details["extra"]:
+        output += details["extra"]
+    if not output:
+        output = src_version
+    return output
+
+
+if __name__ == "__main__":
+    arg_use_tags = "--tags" in sys.argv or bool(os.environ.get("CI_RV_TAGS"))
+    arg_output_json = "--json" in sys.argv
+    output = main(arg_use_tags, arg_output_json)
+    print(output)
--- /dev/null
+++ b/tools/test_tools.py
@@ -0,0 +1,94 @@
+import pathlib
+from importlib.machinery import SourceFileLoader
+from importlib.util import module_from_spec, spec_from_loader
+from unittest import mock
+
+import pytest
+import setuptools
+
+
+from setup_utils import version_to_pep440  # pylint: disable=import-error
+
+try:
+    validate_version = setuptools.dist.Distribution._validate_version  # type: ignore  # noqa: E501
+    setuptools.sic  # pylint: disable=no-member,pointless-statement
+except AttributeError:
+    pytest.skip(
+        "Unable to import necessary setuptools utilities. "
+        "Version is likely too old.",
+        allow_module_level=True,
+    )
+
+# Since read-version has a '-' and no .py extension, we have to do this
+# to import it
+spec = spec_from_loader(
+    "read-version",
+    SourceFileLoader(
+        "read-version",
+        str(pathlib.Path(__file__).absolute().parent / "read-version"),
+    ),
+)
+if not spec:
+    pytest.fail("Could not import read-version")
+read_version = module_from_spec(spec)
+if not spec.loader:
+    pytest.fail("Could not import read-version")
+spec.loader.exec_module(read_version)
+
+
+def assert_valid_version(version):
+    response = validate_version(version)
+    if isinstance(response, setuptools.sic):  # pylint: disable=no-member
+        pytest.fail(f"{version} is not PEP 440 compliant")
+
+
+@pytest.mark.parametrize(
+    "version,expected",
+    [
+        (("23.2", "23.2"), "23.2"),
+        (("23.2", "23.2-0-gcdc24d864"), "23.2-0-gcdc24d86"),
+        (("23.2.1", "23.2.1"), "23.2.1"),
+        (("23.2.1", "23.2.1-0-gcda472559"), "23.2.1-0-gcda47255"),
+        (
+            ("23.2-65-g392346ccd", "23.2-65-g392346ccd"),
+            "23.2-65-g392346cc",
+        ),
+        (
+            ("23.2.1-65-g392346ccd", "23.2.1-65-g392346ccd"),
+            "23.2.1-65-g392346cc",
+        ),
+        (
+            (
+                "cloud-init-23.1.1-2.el8-2-g285d8d80",
+                "cloud-init-23.1.1-2.el8-2-g285d8d80",
+            ),
+            "23.1.1-2-g285d8d80",
+        ),  # RH tags
+        (
+            (
+                "21.1-19-gbad84ad4-0ubuntu1_16.04.4+esm1",
+                "21.1-19-gbad84ad4-0ubuntu1_16.04.4+esm1",
+            ),
+            "21.1-19-gbad84ad4",
+        ),
+        (("0.3.4ubuntu6", "0.3.4ubuntu6"), "0.3.4"),
+        (("noparse", "noparse"), "10.2.1"),
+    ],
+)
+@mock.patch.object(
+    read_version.ci_version, "version_string", return_value="10.2.1"
+)
+class TestReadVersion:
+    def test_tag_parsing(self, _m_package_version, version, expected):
+        """Ensure that we can parse most tags.
+
+        If  we cannot parse the tag, fallback to package version.
+        """
+        with mock.patch.object(
+            read_version, "get_version_from_git", return_value=version
+        ):
+            out = read_version.main()
+        assert out == expected
+
+        # Also ensure it passes setuptools PEP 440 check
+        assert_valid_version(version_to_pep440(out))
--- a/tox.ini
+++ b/tox.ini
@@ -33,6 +33,7 @@ deps =
     types-passlib
     types-PyYAML
     types-requests
+    types-setuptools
     typing-extensions
 
 [pinned_versions]
